# 2.0 Attack Narrative

## 2.2 Reconnaissance


#### Passive Reconnaissance
Passive reconnaissance on the target involves gathering information that is already available on the internet and doing so without directly interacting with the target system.
Methods of passive reconnaissance involve search engine spidering, viewing public DNS records, enumerating website subdomains and links, viewing domain registration information, and services like the [WayBack Machine](https://web.archive.org/). 

- As this is a new application that is being hosted through a hosting company, [Netlify](https://www.netlify.com/), no results were found through passive reconnaissance; Google, WayBack Machine, Bing, Duck Duck Go, or binsearch.info.
![Alt Text](https://dev-to-uploads.s3.amazonaws.com/i/pxmc7nhvswwxl7zlugzq.png)
- [Shodan](https://www.shodan.io/) produced no results related to the application.



#### Active Reconnaissance
Active reconnaissance on the target involved directly probing the target system and retrieving an output.
Methods of active reconnaissance involve fingerprinting the web application, using the Shodan network scanner, performing a DNS forward and reverse lookup, and examining the source code; to name a few.


- [Nmap](https://nmap.org/) produced a few open ports but they were all related specifically to Netlify and is not included in the scope.
- Upon inspecting the request header, the following information was retrieved:
  - The server for the main app is called "Netlify". As this is the hosting company, this makes since.
  - The server from the api is called "Cowboy".
  - (HTTP Strict Transport Security) HSTS is enforced as the site will not load from http. 
  - Web Server header weaknesses were found and will be discussed later in this document.
- When using ZAP to perform an "active scan" on the site nothing new was produced. ![Alt Text](https://dev-to-uploads.s3.amazonaws.com/i/fa7cizvi64uoopqwat2i.png)
- When using ZAP to preform a fuzz for common directory paths, none presented.
- robots.txt file does not exist and the site doesn't have any other pages so nothing else populates.
- Upon signup and login attempt it can be seen that there is traffic to the api at "https://the-trapper-keeper.herokuapp.com/api/v1/users" ![Alt Text](https://dev-to-uploads.s3.amazonaws.com/i/0czyggslaq11o1bspo4h.png)
- While walking through the application the following was observed.
  - An error message of `Please log in` is displayed if you try to access the api directly.
  - Signup and login without parameters cause the site to fail.
  - Login with wrong credentials does not show which part was incorrect. On the site an error message populates saying "unknown username or password" and from the API an error message of `{"error":"ivalid credentials"}` is returned. ![Alt Text](https://dev-to-uploads.s3.amazonaws.com/i/ilt7l2kqv4iowi4z79oh.png) [oops... i spelled 'invalid' wrong...] 
  - When trying to create an account that is already taken a header of `Authorization: Bearer undefined` is returned.
  - When a valid user is created `{"user":{"username":"admin1","password":"admining","email":"admin@admin.com"}}` a lot of information is returned. ![Alt Text](https://dev-to-uploads.s3.amazonaws.com/i/3x1w1v95sezmdqcouhr7.png) It should be noted that headers `Access-Control-Allow-Origin: *` and `Access-Control-Allow-Methods: GET, POST, PUT, PATCH, DELETE, OPTIONS, HEAD` are returned.
  - No cookie is set but there is Session Storage of a JWT. If we decode the JWT it gives information about the user ID and the algorithm used to encrypt it. ![Alt Text](https://dev-to-uploads.s3.amazonaws.com/i/cmszjv8jd2vtd6lk4mjm.png)
  - On refresh the session tokens are deleted and the user must login again. The same happens if a logged in user and tried to directly access a page through the URL the page will again delete the session tokens and the user must login again.
  - Multiple users can sign up with the same password or email.




